{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "num_kelly_instruments=44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_thresh = '2007-02-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_thresh = '2010-02-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = (num_kelly_instruments + num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    comb_df = pd.read_csv(\"s3://senior-essay-economics/transformed-data/factor-model/combined.csv\", index_col=[0,1])\n",
    "    comb_df = comb_df.dropna(how='any', axis=0)\n",
    "    comb_df.to_csv(\"combined-local.csv\")\n",
    "else:\n",
    "    comb_df = pd.read_csv(\"combined-local.csv\", index_col=[0,1])\n",
    "train_df = comb_df.loc[:cv_thresh]\n",
    "cv_df = comb_df.loc[cv_thresh:test_thresh]\n",
    "test_df = comb_df.loc[test_thresh:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator(df, batched=True):\n",
    "    if batched:\n",
    "        for dat in set(df.index.get_level_values(0)):\n",
    "            mtx = df.loc[dat]\n",
    "            ret = tf.cast(mtx[['RET']], tf.float32)\n",
    "            rest = mtx.drop(\"RET\", axis=1)\n",
    "            inp_ivs = tf.cast(rest, tf.float32)\n",
    "            yield rest.values, mtx[['RET']].values\n",
    "    else:\n",
    "        pass\n",
    "        #pnl = df.to_panel()\n",
    "        #df[]\n",
    "        #yield (df.drop(\"RET\", axis=1).values, df[['RET']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pnl = train_df.to_panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    the_dataset=train_df\n",
    "else:\n",
    "    the_dataset = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_step = len(set(the_dataset.index.get_level_values(0))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_generator(lambda: dataset_generator(the_dataset),\n",
    "                                    output_types=(tf.float32, tf.float32), output_shapes=([None, num_topics+num_kelly_instruments], [None, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = ds.shuffle(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING:\n",
    "    ds = ds.repeat(training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = ds.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name='global_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,R = next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = tf.placeholder(tf.float32, [None, num_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"to_factors\", reuse=tf.AUTO_REUSE, initializer=tf.contrib.layers.xavier_initializer()):\n",
    "    W0 = tf.get_variable(\"W\", shape = [num_inputs, num_factors],\n",
    "                        regularizer=None, trainable=True)\n",
    "    F = tf.matmul(X, W0)\n",
    "    F_ext = tf.pad(F, [[0,0], [0,1]], constant_values=1)\n",
    "    Frethat = tf.matrix_solve_ls(F_ext, R, fast=True)\n",
    "    Rpred = tf.matmul(F_ext,Frethat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    eps = (R - Rpred)\n",
    "    loss = tf.reduce_sum(eps * eps)\n",
    "    # regularizer = tf.contrib.layers.l2_regularizer(lambda_l2)\n",
    "    #penalty_new = tf.contrib.layers.apply_regularization(regularizer, new_vars)\n",
    "    #loss = loss + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ret = tf.reduce_mean(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_var = tf.reduce_sum((R - mean_ret)*(R-mean_ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = tf.math.maximum(1. - (loss / (tf.reduce_mean(R*R))), 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batched:\n",
    "    n_steps = len(set(the_dataset.index.get_level_values(0)))* training_epochs\n",
    "else:\n",
    "    n_steps = training_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "model restored\n",
      "Testing Equal-Date-Weighted R^2: 0.0572, Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    if not TRAINING:\n",
    "        saver.restore(sess, \"/tmp/model.ckpt\")\n",
    "        print(\"model restored\")\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    per_losses = []\n",
    "    per_vars = []\n",
    "    with coord.stop_on_exception():\n",
    "        while not coord.should_stop():\n",
    "            best_loss = np.inf\n",
    "            best_step = -1\n",
    "\n",
    "            inp, rets = next_element\n",
    "\n",
    "            feed_dict = {\n",
    "                X: inp,\n",
    "                R: rets\n",
    "            }\n",
    "            if TRAINING:\n",
    "                fetches = [train_op, loss, global_step, per_var] # accuracy\n",
    "                _, loss_val, i, var_val = sess.run(fetches)\n",
    "            else:\n",
    "                fetches = [loss, global_step, per_var] # accuracy\n",
    "                loss_val, i, var_val = sess.run(fetches)\n",
    "            per_losses.append(loss_val)\n",
    "            per_vars.append(var_val)\n",
    "            #if loss_val < best_loss:\n",
    "            #   best_loss = loss_val\n",
    "            #    best_step = i\n",
    "\n",
    "\n",
    "            if i % display_step == 0 and i > 0:\n",
    "                if True:\n",
    "                    the_mean_loss = np.mean(per_losses)\n",
    "                    the_mean_var = np.mean(per_vars)\n",
    "                    mean_r2 = 1. - (the_mean_loss / the_mean_var)\n",
    "                else:\n",
    "                    the_sum_loss = np.sum(per_losses)\n",
    "                    the_sum_var = np.sum(per_vars)\n",
    "                    mean_r2 = 1. - (the_sum_loss / the_sum_var)\n",
    "                    print(\"Different Methodology\")\n",
    "                per_losses = []\n",
    "                per_vars = []\n",
    "                \n",
    "                if TRAINING:\n",
    "                    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "                    phase='Training'\n",
    "                else:\n",
    "                    phase='Testing'\n",
    "                \n",
    "                print(\"%s Equal-Date-Weighted R^2: %.4f, Epoch %i/%i\" % (phase, mean_r2, i // display_step, training_epochs))\n",
    "                \n",
    "            global_step = (global_step + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
